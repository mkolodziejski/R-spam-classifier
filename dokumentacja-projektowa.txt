Wymagania (ze strony Cichosza):

# Do końca przedostatniego tygodnia semestru należy dostarczyć kod źródłowy opracowanego oprogramowania w formie elektronicznej, dokumentację kodu źródłowego w formie elektronicznej oraz dokumentację projektu w formie papierowej, zawierającą:

   1. szczegółową interpretację tematu projektu,
   2. szczegółowy opis wykorzystanych algorytmów,
   3. opis stosowanej procedury eksperymentalnej, w tym:
         1. pytania, na które była poszukiwana odpowiedź,
         2. charakterystyka zbiorów danych, które zostały wykorzystane (oraz ewentualnych czynności związanych z przygotowaniem danych),
         3. parametry algorytmów, których wpływ na wyniki był badany,
         4. sposób oceny jakości modeli,
   4. uzyskane wyniki,
   5. dyskusję wyników i wnioski.


================================================================
Ad. 1 (szczegółowa interpretacja tematu projektu)

    Przedmiotem projektu było stworzenie mechanizmu filtrującego wiadomości email pod kątem wiadomości nieporządanych - spamu. Realizacja polegała na stworzeniu klasyfikatora, który po "nauczeniu się" na zbiorze treningowym, będzie w stanie klasyfikować wiadomości do jednej z dwóch kategorii: spam albo ham (nie-spam).
    W celu osiągnięcia jak największej skuteczności filtrowania wiadomości, wybraliśmy 3 metody klasyfikacji, a następnie porównaliśmy uzyskane za ich pomocą wyniki. W przypadku każdego z algorytmów, postaraliśmy się zbadać wpływ różnych parametrów na jakość klasyfikacji.

Ad. 2 (szczegółowy opis wykorzystanych algorytmów)

    Do klasyfikacji wiadomości wykorzystaliśmy trzy algorytmy:
1) Naiwny Klasyfikator Bayesa 
	W przypadku tego algorytmu, wykorzystaliśmy gotową implementację w postaci funkcji 'naiveBayes' z biblioteki 'e1071'. Przed tym wyborem, podjęliśmy próbę wykorzystania podobnej funkcji ('NaiveBayes') z biblioteki 'klaR', lecz dawała ona znacznie gorsze rezultaty. Wykorzystywana przez nas implementacja posiada jedną wadę - w przypadku tak dużego zbioru przetwarzanych danych, prawdopodobieństwa a posteriori zwracane przez funkcję 'predict' w zdecydowanej większości przypadków miały wartość 'NaN'. Błąd ten (jak przypuszczamy - w bibliotece e1071) uniemożliwił nam stworzenie wykresów ROC dla klasyfikacji bayesowskiej. Zarówno do uczenia, jak i do klasyfikacji, dane przekształcane były do postaci macierzy binarnej, a więc pod uwagę był brany jedynie fakt wystąpienia danego słowa w dokumencie, lub jego brak. Dane w takiej postaci dawały lepsze wyniki klasyfikacji, niż macierz przechowująca liczbę wystąpień słów w dokumentach.

2) Klasyfikator k-Najbliższych Sąsiadów
	Algorytm kNN klasyfikuje przykłady znajdując ich najbliższe otoczenie w zbiorze trenującym oraz agregując klasy występujących w tym otoczeniu k przykładów uczących. Otoczenie jest określane przez wybraną miarę (nie)podobieństwa, np. odległośc euklidesową lub kosinusową, która szczególnie dobrze sprawdza się w problemach klasyfikacji tekstu. Najczęściej stosowane są dwa sposoby agregacji kategorii, w zależności od wartości jakie może ona przyjmowac. Do przewidywania atrybutów ciągłych lub uporządkowanych można zastosowac uśrednianie, a w przypadku klas dyskretnych najczęściej stosuje się wybór większościowy (głosowanie).
	W ramach projektu, ze względu na brak satysfakcjonującego, gotowego rozwiązania, zaimplementowaliśmy algorytm kNN umożliwiający zmianę zarówno miary niepodobieństwa między dokumentami, jak i sposobu agregacji klas. Zwracane wartości, poza wektorem klas, obejmują także sąsiedztwo (identyfikatory, klasy przykładów ze zbioru uczącego oraz odległości od klasyfikowanego przykładu), na podstawie którego dana klasa została wybrana. Aby zapewnic jak najlepsze wykrywanie najbliższego otoczenia dokumentów, macierz wystąpień słów w poszczególnych przykładach jest normalizowana przez liczbę słów w poszczególnych dokumentach, tworząc macierz częstości występowania słowa w dokumentach.

3) Klasyfikator k-Najbliższych Sąsiadów Pracujący w Przestrzeni LSA
	Zarówno naiwny klasyfikator bayessowski, jak i prosty klasyfikator kNN nie biorą pod uwagę potencjalnych zależności między słowami, jak chociażby występowanie synonimów słów. Aby rozwiązac ten problem można zastosowac metodę Analizy Semantyki Ukrytej (Latent Semantic Analysis - LSA), która próbuje stworzyc przestrzeń pseudo-słów (ang. concept space), które reprezentują grupy słów występujących w podobym kontekście. Polega ona na dekompozycji SVD macierzy wystąpień słów na iloraz trzech macierzy, które definiują przestrzeń LSA:
	A = T S t(D)
Macierze T i D są ortogonalne oraz zawierają wektory osobliwe macierzy A, natomiast S jest macierzą diagonalną zawierającą wartości osobliwe macierzy A w kolejności malejącej. Reprezentację dokumentu w przestrzeni pseudo-słów można otrzymac w wyniku przekształcenia:
	d' = S^-1 t(T) d,
gdzie d jest wektorem częstości występowania słów w danym dokumencie, a d' jest wynikowym wektorem korelacji z pseudo-słowami LSA. Otrzymane w ten sposób wektory są dalej wykorzystywane bezpośrednio przez klasyfikator kNN.
	Dodatkową zaletą dekompozycji SVD w metodzie LSA jest możliwość zmniejszenia wymiarów danych. Wartości osobliwe wskazują jak dużo informacji przekazuje dane pseudo-słowo, tak więc możemy odrzucic te (wartosci osobliwe), które nie są istotne dla dalszego przetwarzania, np. pozostawiając tylko słowa, które przenoszą łącznie określony procent informacji.
	W projekcie została zastosowana gotowa implementacja z pakietu 'lsa'.



Ad. 3 (opis stosowanej procedury eksperymentalnej)


Charakterystyka zbiorów danych

    Danymi do uczenia oraz testowania były zbiory "surowych" wiadomości email pochodzące ze SpamAssassin Public Corpus. Wśród nich występują zestawy wiadomości oznaczonych jako niepożądane ("spam") oraz zestawy wiadomości pożądanych ("ham"). Wiadomości pożądane są dodatkowo podzielone wg trudności, tzn. podobieństwa do wiadomości niepożądanych, na łatwe i trudne. Zbiory uczące oraz testowe były tworzone losowo spośród wszystkich wiadomości, lecz zachowując pożądaną proporcję spamu w stosunku do nie-spamu.
    W ramach przetwarzania wstępnego usunięte zostały wszelkie nagłówki wiadomości email, liczby oraz ewentualne znaczniki html, pozostawiając do analizy jedynie treść dokumentu. Podczas wczytywania wiadomości (z wykorzystaniem zmodyfikowanej funkcji 'textmatrix' z pakietu 'lsa') usuwane były nieistotne z punktu widzenia treści słowa ("stopwords"), słowa zbyt rzadkie oraz zbyt powszechne (progi określane były procentowo, w większości przypadków jako występujące w odpowiednio <1% i >65% wszystkich wiadomości). Na pozostałych słowach przeprowadzany był "stemming", aby ujednolicić wiele odmian tych samych słów. Dokumenty, które po zastosowaniu wyżej wymienionych filtrów nie posiadają rzadnych słów, są odrzucane. 
	Ostatecznym formatem danych, na którym pracowały klasyfikatory, jest "data frame" zawierający macierz liczby wystąpień słów w poszczególnych dokumentach, przy czym atrybutami (kolumnami) są kolejne słowa spełniające wcześniej wymienione kryteria, a przykładami (wierszami) są załadowane dokumenty.


Parametry algorytmów, których wpływ na wyniki był badany

    Podczas eksperymentów sprawdzany był wpływ różnych parametrów wykorzystywanych algorytmów na jakość klasyfikacji:
1) Naiwny Klasyfikator Bayesowski
    - prawdopodobieństwo a-priori spamu - ze wzgledu na wykorzystanie już istniejącej implementacji tego klasyfikatora, wpływ prawdopodobieństwa a-priori symulowany był poprzez zwiększenie liczby wiadomości niepożądanych w stosunku do pożądanych w zbiorze treningowym. Przetestowane zostały trzy warianty: stosunek 1:1, 3:2 oraz 7:3. 
    - próg prawdopodobieństwa - prawdopodobieństwo wystąpienia słowa w dokumencie w przypadku jego braku. Sprawdzone zostały trzy wartości: 0.005, 0.01 oraz 0.05.

2) Klasyfikator k-Najbliższych Sąsiadów
	- k - liczba dokumentów z otoczenia klasyfikowanego przykładu, które są brane pod uwagę przy wyznaczaniu kategorii.
	- miara odległości wyznaczająca sąsiedztwo przykładów - w ramach eksperymentów użyte zostały: 
		- miara euklidesowa 
			d = sqrt( suma<i>((ai(x1)-ai(x2))^2) )
		- miara kosinusowa 
			d = 1 - (x1*x2) / (|x1|*|x2|)
	- próg pewnosci wymaganej, aby sklasyfikowac przykład jako "spam"

3) Klasyfikator k-Najbliższych Sąsiadów Pracujący w Przestrzeni LSA
	- miara odległości wyznaczająca sąsiedztwo przykładów w przestrzeni LSA - podobnie jak w poprzednim przypadku zostały wykorzystane miary euklidesowe i kosinusowe
	 - poziom redukcji wymiarów przestrzeni LSA - wybierane jest tyle największych wartości osobliwych (wskazujących na najważniejsze pseudo-słowa), aby ich suma, w stosunku do sumy wszystkich wartości, przekroczyła pożądany próg.


Sposób oceny jakości modeli

    Oceniana była przede wszystkim skuteczność klasyfikatora, a więc procent poprawnych odpowiedzi na zbiorze testowym. Dodatkowo zmierzona została wydajność poszczególnych klasyfikatorów oraz przeanalizowano wpływ parametrów klasyfikatorów na występowanie błędów false-positive i false-negative. W przypadku naiwnego klasyfikatora bayesowskiego, aby wpłynąc na liczbę błędów false-positive wykorzystaliśmy zmianę prawdopodobnieństw a-priori poszczególnych kategorii - "spamu" i "hamu". W przypadku klasyfikatorów najbliższego sąsiedztwa zastosowaliśmy zmianę wymaganej pewności klasyfikacji "spamu".


Uzyskane wyniki

    Testy wszystkich algorytmów odbywały się wykorzystując 5-krotną krzyżową walidację na zbiorze danych zawierającym 2000 dokumentów i co najwyżej 1000 wykrytych, najczęściej występujących słów. Ilość dokumentów, na których przeprowadzaliśmy testy wpływu poszczególnych parametrów na jakość klasyfikacji, zależała od wydajności poszczególnych algorytmów:
    - dla klasyfikatora kNN z wykorzystaniem LSA: rozmiar danych podany powyżej
	- dla naiwnego klasyfikatora bayesowskiego: 1000 dokumentów
	- dla prostego klasyfikatora kNN: 1000 dokumentów, maksymalnie 750 słów

1) naiwny klasyfikator bayesowski
    Dla tego klasyfikatora osiągnięty został wynik w przybliżeniu 92% poprawnych odpowiedzi (91,9839%).
    Zmiana prawdopodobieństwa a-priori spamu pogarszała podany powyżej wynik. Przy stosunku 3:2 spamu do hamu, skuteczność klasyfikatora spadła do 72%. Dalsze zwiększenie ilosci spamu podczas uczenia do stosunku 7:3 skutkowało uzyskaniem klasyfikatora niemal bezużytecznego - jego skuteczność wyniosła 53%.

2) Klasyfikator k-Najbliższych Sąsiadów
	

3) Klasyfikator k-Najbliższych Sąsiadów w Przestrzeni LSA


Podsumowanie
	
